{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41310193-7650-43b2-a916-241c34aab538",
   "metadata": {},
   "source": [
    "# Executors and Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597d38b-e0ff-406b-8eaa-08344b296d26",
   "metadata": {},
   "source": [
    "This notebook has a brief explanation of how we are going to create generic **Classes** capable of handling important Data Lake jobs. *E.g.*, transferring data from different storages, creating tables on **AWS Athena** and **AWS Redshift**, managing **Glue Jobs**, *etc*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826317a0-cf3b-4784-972e-7b52bc84cd4a",
   "metadata": {},
   "source": [
    "## Staging Data with a optional transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd4d55-1968-4e25-917b-f3228e494a75",
   "metadata": {},
   "source": [
    "The class we are creating below is capable of taking data from a parent directory and moving it to a dump directory. Furthermore, given a python script, it will run it with its respective arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262fd28d-b200-4224-8216-f5526a513fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StagingExecutor:\n",
    "    \n",
    "    def __init__(self, parent_directory: str, dump_directory: str, archive_or_delete: str = \"archive\", py_exec_path: str = None, py_exec_args: dict = None) -> None:\n",
    "        self.parent = parent_directory\n",
    "        self.dump = dump_directory\n",
    "        self.archive_or_delete = archive_or_delete\n",
    "        self.py_exec_path = py_exec_path\n",
    "        self.py_exec_args = py_exec_args\n",
    "\n",
    "    def transfer(self) -> None:\n",
    "        \n",
    "        if not self.py_exec_path:\n",
    "            print('No transformation required. Moving file using only parent and dump')\n",
    "        \n",
    "        elif self.py_exec_path:\n",
    "            import sys\n",
    "            sys.path.insert(1, self.py_exec_path)\n",
    "            import py_exec\n",
    "            \n",
    "            py_exec.test()\n",
    "            \n",
    "            if not self.py_exec_args:\n",
    "                print('Python Executor does not require arguments')\n",
    "            \n",
    "            elif self.py_exec_args:\n",
    "                print(f'Python Executor is running with the following parameters:\\n{self.py_exec_args}')\n",
    "                py_exec.main(self.parent, self.dump, **self.py_exec_args)\n",
    "                \n",
    "    def post_staging(self) -> None:\n",
    "                \n",
    "        if self.archive_or_delete == 'archive':\n",
    "            print('File from landing will be moved to archive folder')\n",
    "        \n",
    "        elif self.archive_or_delete == 'delete':\n",
    "            print('File will be deleted from landing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48db1f8b-3fa5-4b58-b4d0-f07439388b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, r'..')\n",
    "\n",
    "import executors\n",
    "\n",
    "f = '../routines/test_routine/routine_config.json'\n",
    "\n",
    "with open(f, 'r') as j:\n",
    "    routine_config = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175257bd-2117-48f5-8d82-d595a2a15b07",
   "metadata": {},
   "source": [
    "# Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2446b1f-f7fa-433a-86e0-a248a2fe340c",
   "metadata": {},
   "source": [
    "Data orchestration is a relatively new concept to describe the set of technologies that abstracts data access across storage systems, virtualizes all the data, and presents the data via standardized APIs with a global namespace to data-driven applications. There is a clear need for data orchestration because of the increasing complexity of the data ecosystem due to new frameworks, cloud adoption/migration, as well as the rise of data-driven applications. [[Data Orchestrator]](https://dzone.com/articles/data-orchestration-its-open-source-but-what-is-it)\n",
    "\n",
    "The Orchestrator is a class that will follow the routine_config.json, where one will declare which executors and their respective tasks to run. The model for our routine_config is:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"routine_name\": <ROUTINE_NAME>,\n",
    "    \"executors\": {\n",
    "        <EXECUTOR_CLASS:  {\n",
    "            \"params\":<__init__ PARAMETERS>,\n",
    "            \"tasks\": <LIST_SELECTED_TASKS_FROM_EXECUTOR>\n",
    "        }\n",
    "    }\n",
    "}   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623ac9f6-4624-4030-aad7-c0d060e77cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Orchestrator:\n",
    "    \n",
    "    def __init__(self, routine_config: dict) -> None:\n",
    "        self.routine_config = routine_config\n",
    "    \n",
    "    def run_executors(self):\n",
    "        for executor in routine_config['executors']:\n",
    "            self.executor_name = executor\n",
    "            klass = globals()[self.executor_name]\n",
    "            self.executor = klass(**routine_config['executors'][self.executor_name]['params'])\n",
    "            self.run_tasks()\n",
    "            \n",
    "    def run_tasks(self):\n",
    "        for task in routine_config['executors'][self.executor_name]['tasks']:\n",
    "            getattr(self.executor, task)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc37eba-4451-46f4-8b78-cce8ff37d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = Orchestrator(routine_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c04232b-8a1c-4623-9750-0e29848e120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is running inside other module, and being executed because of a call.\n",
      "For compliance: Hello World (◕‿◕✿)\n",
      "Test ok\n",
      "Python Executor is running with the following parameters:\n",
      "{'mapper': {'column1': 'name', 'column2': 'age', 'column3': 'job'}}\n",
      "File will be deleted from landing\n"
     ]
    }
   ],
   "source": [
    "orchestrator.run_executors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3c54f-fb33-46cf-9bd0-8996685ac9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

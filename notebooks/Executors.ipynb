{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41310193-7650-43b2-a916-241c34aab538",
   "metadata": {},
   "source": [
    "# Executors and Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597d38b-e0ff-406b-8eaa-08344b296d26",
   "metadata": {},
   "source": [
    "This notebook has a brief explanation of how we are going to create generic **Classes** capable of handling important Data Lake jobs. *E.g.*, transferring data from different storages, creating tables on **AWS Athena** and **AWS Redshift**, managing **Glue Jobs**, *etc*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826317a0-cf3b-4784-972e-7b52bc84cd4a",
   "metadata": {},
   "source": [
    "## Staging Data with a optional transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd4d55-1968-4e25-917b-f3228e494a75",
   "metadata": {},
   "source": [
    "The class we are creating below is capable of taking data from a parent directory and moving it to a dump directory. Furthermore, given a python script, it will run it with its respective arguments. This is a good option for a before hand cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262fd28d-b200-4224-8216-f5526a513fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StagingExecutor:\n",
    "    \n",
    "    def __init__(self, parent_directory: str, dump_directory: str, archive_or_delete: str = \"archive\", py_exec_path: str = None, py_exec_args: dict = None) -> None:\n",
    "        self.parent = parent_directory\n",
    "        self.dump = dump_directory\n",
    "        self.archive_or_delete = archive_or_delete\n",
    "        self.py_exec_path = py_exec_path\n",
    "        self.py_exec_args = py_exec_args\n",
    "\n",
    "    def transfer(self) -> None:\n",
    "        \n",
    "        if not self.py_exec_path:\n",
    "            print('No transformation required. Moving file using only parent and dump')\n",
    "        \n",
    "        elif self.py_exec_path:\n",
    "            import sys\n",
    "            sys.path.insert(1, self.py_exec_path)\n",
    "            import py_exec\n",
    "            \n",
    "            if not self.py_exec_args:\n",
    "                print('Python Executor does not require arguments')\n",
    "            \n",
    "            elif self.py_exec_args:\n",
    "                print(f'Python Executor is running with the following parameters:\\n{self.py_exec_args}')\n",
    "                py_exec.main(self.parent, self.dump, **self.py_exec_args)\n",
    "                \n",
    "    def post_staging(self) -> None:\n",
    "                \n",
    "        if self.archive_or_delete == 'archive':\n",
    "            print('File from landing will be moved to archive folder')\n",
    "        \n",
    "        elif self.archive_or_delete == 'delete':\n",
    "            print('File will be deleted from landing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9412a50-840b-457c-86bb-e98f35a8729f",
   "metadata": {},
   "source": [
    "## Downloader with unzip functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdeaa32-3c63-4c7d-86cf-fd3d7e06087e",
   "metadata": {},
   "source": [
    "This executor will take directories as main arguments, and download them into a landing folder (local or on **S3**) using *requests*. Notwithstanding downloading, it can be set to unzip and organize raw data for a cleaner staging task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "116a94f6-f0a9-4ba3-a306-5df621b9e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "\n",
    "\n",
    "class DownloaderExecutor:\n",
    "    def __init__(self, requests_arguments: dict, landing_directory: str, unzip: str = None) -> None:\n",
    "        self.requests_arguments = requests_arguments ##A dictionary such as: {\"url\": URL, \"params\": PARAMS, ...}\n",
    "        self.landing_directory = landing_directory ##With file name in case of unzipped, without in case of zipped\n",
    "        self.unzip = unzip\n",
    "        self.res = None\n",
    "        \n",
    "        # self.py_exec_path = py_exec_path\n",
    "        # self.py_exec_args = py_exec_args\n",
    "        \n",
    "    def download(self):\n",
    "        self.res = requests.get(**self.requests_arguments)\n",
    "        \n",
    "        if self.unzip == \"unzip\":\n",
    "            print('Will have to unzip')\n",
    "            temp = zipfile.ZipFile(io.BytesIO(self.res.content))\n",
    "            temp.extractall(self.landing_directory)\n",
    "            \n",
    "            \n",
    "        elif not self.unzip:\n",
    "            print('Does not unzip')\n",
    "            with open(self.landing_directory, 'wb') as temp:\n",
    "                temp.write(self.res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497122b4-3946-4267-828b-397d6d1f2872",
   "metadata": {},
   "source": [
    "To test de unzip functionallity, we are using the following dataset: https://www.stats.govt.nz/assets/Uploads/Retail-trade-survey/Retail-trade-survey-September-2020-quarter/Download-data/retail-trade-survey-september-2020-quarter-csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d387011-5eab-4388-ab58-60b3a5523139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will have to unzip\n"
     ]
    }
   ],
   "source": [
    "downexec = {\"requests_arguments\": {\"url\": \"https://www.stats.govt.nz/assets/Uploads/Retail-trade-survey/Retail-trade-survey-September-2020-quarter/Download-data/retail-trade-survey-september-2020-quarter-csv.zip\"}, \"landing_directory\": \"../data/landing\", \"unzip\": \"unzip\"}\n",
    "klass = DownloaderExecutor(**downexec)\n",
    "klass.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175257bd-2117-48f5-8d82-d595a2a15b07",
   "metadata": {},
   "source": [
    "# Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2446b1f-f7fa-433a-86e0-a248a2fe340c",
   "metadata": {},
   "source": [
    "Data orchestration is a relatively new concept to describe the set of technologies that abstracts data access across storage systems, virtualizes all the data, and presents the data via standardized APIs with a global namespace to data-driven applications. There is a clear need for data orchestration because of the increasing complexity of the data ecosystem due to new frameworks, cloud adoption/migration, as well as the rise of data-driven applications. [[Data Orchestrator]](https://dzone.com/articles/data-orchestration-its-open-source-but-what-is-it)\n",
    "\n",
    "The Orchestrator is a class that will follow the routine_config.json, where one will declare which executors and their respective tasks to run. The model for our routine_config is:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"routine_name\": <ROUTINE_NAME>,\n",
    "    \"executors\": {\n",
    "        <EXECUTOR_CLASS>:  {\n",
    "            \"params\":<__init__ PARAMETERS>,\n",
    "            \"tasks\": <LIST_SELECTED_TASKS_FROM_EXECUTOR>\n",
    "        }\n",
    "    }\n",
    "}   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623ac9f6-4624-4030-aad7-c0d060e77cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Orchestrator:\n",
    "    \n",
    "    def __init__(self, routine_config: dict) -> None:\n",
    "        self.routine_config = routine_config\n",
    "    \n",
    "    def run_executors(self):\n",
    "        for executor in routine_config['executors']:\n",
    "            self.executor_name = executor\n",
    "            klass = globals()[self.executor_name]\n",
    "            self.executor = klass(**routine_config['executors'][self.executor_name]['params'])\n",
    "            self.run_tasks()\n",
    "            \n",
    "    def run_tasks(self):\n",
    "        for task in routine_config['executors'][self.executor_name]['tasks']:\n",
    "            getattr(self.executor, task)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3c54f-fb33-46cf-9bd0-8996685ac9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

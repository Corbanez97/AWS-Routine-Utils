{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41310193-7650-43b2-a916-241c34aab538",
   "metadata": {},
   "source": [
    "# Executors and Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597d38b-e0ff-406b-8eaa-08344b296d26",
   "metadata": {},
   "source": [
    "This notebook has a brief explanation of how we are going to create generic **Classes** capable of handling important Data Lake jobs. *E.g.*, transferring data from different storages, creating tables on **AWS Athena** and **AWS Redshift**, managing **Glue Jobs**, *etc*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826317a0-cf3b-4784-972e-7b52bc84cd4a",
   "metadata": {},
   "source": [
    "## Staging Data with a optional transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd4d55-1968-4e25-917b-f3228e494a75",
   "metadata": {},
   "source": [
    "The class we are creating below is capable of taking data from a parent directory and moving it to a dump directory. Furthermore, given a python script, it will run it with its respective arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "262fd28d-b200-4224-8216-f5526a513fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StagingExecutor:\n",
    "    \n",
    "    def __init__(self, parent_directory: str, dump_directory: str, archive_or_delete: str = \"archive\", py_exec_path: str = None, py_exec_args: dict = None) -> None:\n",
    "        self.parent = parent_directory\n",
    "        self.dump = dump_directory\n",
    "        self.archive_or_delete = archive_or_delete\n",
    "        self.py_exec_path = py_exec_path\n",
    "        self.py_exec_args = py_exec_args\n",
    "\n",
    "    def transfer(self) -> None:\n",
    "        \n",
    "        if not self.py_exec_path:\n",
    "            print('No transformation required. Moving file using only parent and dump')\n",
    "        \n",
    "        elif self.py_exec_path:\n",
    "            import sys\n",
    "            sys.path.insert(1, self.py_exec_path)\n",
    "            import py_exec\n",
    "            \n",
    "            py_exec.test()\n",
    "            \n",
    "            if not self.py_exec_args:\n",
    "                print('Python Executor does not require arguments')\n",
    "            \n",
    "            elif self.py_exec_args:\n",
    "                print(f'Python Executor is running with the following parameters:\\n{self.py_exec_args}')\n",
    "                py_exec.main(self.parent, self.dump, **self.py_exec_args)\n",
    "                \n",
    "    def post_staging(self) -> None:\n",
    "                \n",
    "        if self.archive_or_delete == 'archive':\n",
    "            print('File from landing will be moved to archive folder')\n",
    "        \n",
    "        elif self.archive_or_delete == 'delete':\n",
    "            print('File will be deleted from landing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48db1f8b-3fa5-4b58-b4d0-f07439388b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'parent_directory': r'/home/corbanez/Documents/Data Engineering using AWS/data/raw_data.csv', \\\n",
    "            'dump_directory': r'/home/corbanez/Documents/Data Engineering using AWS/data/clean_data.csv', \\\n",
    "                #'archive_or_delete': 'delete', \\\n",
    "                     'py_exec_path': r'../executors', \\\n",
    "                          'py_exec_args': {'mapper': {'column1':'name', 'column2':'age', 'column3':'job'}}}\n",
    "\n",
    "task = StagingExecutor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2660ecfb-9463-4cd5-a4eb-3baf074e4722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ok\n",
      "Python Executor is running with the following parameters:\n",
      "{'mapper': {'column1': 'name', 'column2': 'age', 'column3': 'job'}}\n",
      "File from landing will be moved to archive folder\n"
     ]
    }
   ],
   "source": [
    "task.transfer()\n",
    "\n",
    "task.post_staging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b87aa9d-3482-437f-9d80-759759fec661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ok\n",
      "Python Executor is running with the following parameters:\n",
      "{'mapper': {'column1': 'name', 'column2': 'age', 'column3': 'job'}}\n",
      "File from landing will be moved to archive folder\n"
     ]
    }
   ],
   "source": [
    "routine_config = {'routine_name': 'Test Ingestion with py_exec', \\\n",
    "                    'tasks': {'StagingExecutor': {'params': params, \\\n",
    "                                                     'sub_tasks': ['transfer', 'post_staging']}}\n",
    "\n",
    "for method in routine_config['sub_tasks']:\n",
    "    getattr(task, method)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b97883-ad77-48b1-82ff-6bbf22052af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
